{
  "hash": "c0500790b57eba419352f6316836da12",
  "result": {
    "engine": "knitr",
    "markdown": "\n\n\n\n# (PART) Data Acquisition & Cleaning {-}\n\n# Data Import\n\n## Learning Goals {-}\n\n- Develop comfort in finding an existing data set to import into R\n- Develop comfort in importing data of a variety of file types into R\n- Understand and implement the data cleaning process to make values consistent\n- Understand the implications of different ways of dealing with missing values with `replace_na` and `drop_na`\n\n\nCreate a new Rmd file (save it as 12-Data Import.Rmd). Put this file in a folder `Assignment_08` in your `COMP_STAT_112` folder.\n- Make sure to add alt text to visualizations using fig.alt!\n\n\n## Finding, Importing, and Cleaning Data {-}\n\nAdditional resources and readings:   \n1. [Data Import Cheat Sheet](https://github.com/rstudio/cheatsheets/raw/main/data-import.pdf)    \n2. [`readr` documentation](https://readr.tidyverse.org/)   \n3. [Data import](http://r4ds.had.co.nz/data-import.html) from Wickham and Grolemund <br/>\n4. [Missing data](http://r4ds.had.co.nz/tidy-data.html#missing-values-3) from Wickham and Grolemund <br/>\n5. [Data intake](https://mdsr-book.github.io/mdsr2e/ch-dataII.html#data-intake) from Baumer, Kaplan, and Horton   \n6. [Using the import wizard](https://www.youtube.com/watch?v=GtCsjtZBNp4) from Prof. Lendway\n\n\n\n\nIn practice, data science is not as glamorous as building fancy classifiers and creating visualizations all the time. Data scientists spend [80% of their time acquiring and cleaning data](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#755d4d426f63). While the skill of data acquisition is best learned through experience, this section of the course will outline the most common approaches to acquiring data.\n\nWhen importing and cleaning a dataset, take careful notes in your R Markdown. Explain where you found the dataset (the source). Record the steps you took to clean and import the data in case somebody else needs to replicate your analysis. You should also make sure to cite and credit the creator of the dataset.\n\n### Finding Existing Data Sets {-}\n\n\n\n::: {.cell fig.margin='true'}\n::: {.cell-output .cell-output-error}\n\n```\nError in knitr::include_graphics(\"images/csv_search.jpeg\"): Cannot find the file(s): \"images/csv_search.jpeg\"\n```\n\n\n:::\n:::\n\n\n\nThe easiest way to get data is by finding an existing dataset that has been created by somebody else. Search engines such as Google can be excellent tools, especially when using file type filters. For example, if you are looking for a dataset about movie reviews, you might search for \"`movie reviews filetype:csv`\". You could also try searching for other common filetypes that are compatible with R, such as `.tsv`, `.xls`, `.xlsx`, or `.rds`.\n\n\nAnother good resource for datasets are compendiums of datasets such as the excellent and continuously-evolving [awesome-public-datasets](https://github.com/caesar0301/awesome-public-datasets) GitHub repo, [Kaggle datasets](https://www.kaggle.com/datasets) or the [data.world website](https://data.world/) website. You can find links to other similar compendiums at the end of the awesome-public-datasets page.\n\n### Saving Datasets Locally {-}\n\nOnce you've found a dataset you are interested in, you need to download the file and save it to a location on your computer.\n\nThe best location to put a dataset is within a folder that is dedicated to the project or assignment. For example, you've created a folder for `Assignment_08` and any datasets you use for this assignment should be saved in that folder. \n\nQuick Note: One key idea when you are working with datasets on your local machine is that you need to:\n\n- know where the files are located \n- know how to tell the computer program where the files are located (a file path)\n\nThere are two common ways we refer to file locations: absolute file path and relative file path.\n\n**Absolute file path**\n\n- An absolute file path describes the location of a file from the root directory or folder, typically the user directory. \n  - On a Mac, `~` refers to the user root directory.\n  - On a Windows, the root directory is typically `C:\\`\n- Example: A file called `data.csv` is located in the `Assignment_08` folder in `Comp_Stat_112` folder on the Desktop\n  - On a Mac, the absolute file path is `~/Desktop/Comp_Stat_112/Assignment_08/data.csv`\n  - On a Windows, the absolute file path is `C:/Desktop/Comp_Stat_112/Assignment_08/data.csv`\n  - *Windows Note: Switch from backslash to forward slashes in R or you need to use \\\\ instead of \\*\n  \n**Relative file path**\n\n- A relative file path describes the location of a file from the current working directory (or in the case of an Rmd, the location of the Rmd file).\n  - When working within an Rmd file, it will first look for files relative to the location of the Rmd file. Therefore, it is good practice to put the data file in the same folder as the Rmd file you are working on.\n  - If you are working in the Console, you can change the working directory (Session > Set Working Directory).\n- Example: A file called `data.csv` is located in a `data` folder within `Comp_Stat_112` folder on the Desktop\n  - If the working directory is `~/Desktop/Comp_Stat_112/Assignment_08/`, the relative path is `../data/data.csv`. The `..` refers to the parent directory (go up one level to the folder containing `Assignment_08`).\n  - If the working directory is `~/Desktop/Comp_Stat_112/`, the relative path is `data/data.csv`.\n  - If the working directory is `~/Desktop/Comp_Stat_112/data`, the relative path is `data.csv`.\n\n\n\n### Loading Datasets {-}\n\nOnce you have a dataset, it's time to load it into `R`. Don't be frustrated if this step takes some time. \n\nThe table below lists some common data import functions and when you would use them.\n\nFunction | Use when\n-----------|---------------\n`read_csv()`| data are saved in .csv (comma delimited or comma separated values) format - you can save Excel files and Google Sheets in this format \n`read_delim()` | data are saved in other delimited formats (tab, space, etc.)  \n`read_sheet()` | data are in a Google Sheet  \n`st_read()` | reading in a shapefile\n\nA few tips:\n\n * When reading in data from a file, one tip is to initially use the Import Wizard to help write the code and file path. DO NOT use it to import the data as you will need the code to read in the data in order to knit your document. Check out a [video tutorial on the Import Wizard](https://www.youtube.com/embed/GtCsjtZBNp4)   \n * The import functions `read_csv`, `read_csv2`, and `read_tsv` from the `readr` package are faster than their counterparts `read.csv`, `read.csv2`, and `read.tsv` from the `base` package for large files. They also have more flexible parsers (e.g., for dates, times, percentages). We recommend you use these functions instead of the `base` functions like `read.csv`. The package `fread` has other import functions and is also faster for large datasets. For smaller data sets (say 1MB or less), there won't be that much difference in time for the three different packages. \n * `read_csv2` is for semi-colon delimited files, whereas `read_csv` is for comma delimited files.\n * The `readr` functions automatically guess the type of data in each column (e.g., character, double, integer). You will often see a message just after the import telling you what it chose for each column. If you think there is an issue, you can use the function `problems()` to detect problems, and/or specify how the columns should be imported. See the section on \"column specification\" in the [Data Import Cheat Sheet](https://github.com/rstudio/cheatsheets/raw/main/data-import.pdf) for more info.\n * If you have trouble importing a dataset, try to first import it into a different data such as Google Sheets or Excel tool and then export it as a TSV or CSV before reading it into `R`.\n * For really messy data, [OpenRefine](http://openrefine.org/) is complicated but powerful ([YouTube demo](https://www.youtube.com/watch?v=WCRexQXYFrI)). \n * When you are importing a large file, you might want to first try importing a subset of the data. For example, if you want to take the first 17 rows only, you can write `read_csv(\"file.csv\",n_max=17)`\n * Similarly, you might want to skip the first $n$ lines of the file when importing, select only certain columns to read in, or choose a random subset of the rows. See the cheat sheet for instructions on these tasks or just google!\n\n### Checking the Imported Datasets {-}\n\nAfter reading in new data, it is ALWAYS a good idea to do some quick checks of the data. Here are two first steps that are especially useful:\n\n1. Open the data in the spreadsheet-like viewer with `View(dataset_name)` and take a look at it. Sort it by different variables by clicking on the arrows next to the variable name. Make sure there isn't anything unexpected.\n\n2. Do a quick summary of the data. The code below is one way to do this. For quantitative variables, it provides summary statistics and will let you know if there are missing values. For factors (they need to be factors, not just character variables - the `mutate()` changes them to factors), it shows you counts for the top categories and tells you if there are any missing values. \n\n```\ndataset_name %>% \n  mutate(across(where(is.character), as.factor)) %>% \n  summary()\n```\n\n\n### Cleaning Datasets {-}\n\n**Cleaning Categorical Variables**\n\nFirst we want to make sure the factors are \"clean\", meaning consistent values in the correct format. For example, `true` and `TRUE` and `T` will be three different factors. The easiest way to manage this is to look at the levels for the factor and replace values with a messy factor to a clean one. For example, the following code cleans up values in true/false values in column `X` in a data set called `df`:\n\n```\ndf <- df %>% mutate(X = fct_recode(X, \"TRUE\" = \"T\", \"TRUE\" = \"true\", \"FALSE\" = \"f\", \"FALSE\" = \"N\", \"FALSE\" = \"No\"))\n```\n\n\n\n::: {.cell name='Clean up the levels on the Messy IMDB 5000 dataset'}\n\n```{.example .cell-code}\nWe will use a slightly \"messied\" [version](data/imdb_5000_messy.csv) of the [IMDB 5000 Dataset](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset), collected by chuansun76 on Kaggle.^[Another option for part (e) would be to leave them as strings and then use string processing to define the levels. We'll learn this technique soon.]\n```\n:::\n\n\n\na. Download the csv file of the IMDB 5000 dataset from \"https://bcheggeseth.github.io/112_spring_2023/data/imdb_5000_messy.csv\" (right-click, save file as), put it in your `Assignment_08` folder, use `read_csv` to load it into RStudio, and save it as `imdbMessy` in R.\n\n<details>\n  <summary>Solution</summary>\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nimdbMessy <- read_csv(\"imdb_5000_messy.csv\") # Relative Path: If your Rmd file and csv file are in the same folder\n```\n:::\n\n\n  \n</details>\n\\  \nb. Print out the variable names.\n\n<details>\n  <summary>Solution</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(imdbMessy) #order = order in dataset\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"...1\"                      \"color\"                    \n [3] \"director_name\"             \"num_critic_for_reviews\"   \n [5] \"duration\"                  \"director_facebook_likes\"  \n [7] \"actor_3_facebook_likes\"    \"actor_2_name\"             \n [9] \"actor_1_facebook_likes\"    \"gross\"                    \n[11] \"genres\"                    \"actor_1_name\"             \n[13] \"movie_title\"               \"num_voted_users\"          \n[15] \"cast_total_facebook_likes\" \"actor_3_name\"             \n[17] \"facenumber_in_poster\"      \"plot_keywords\"            \n[19] \"movie_imdb_link\"           \"num_user_for_reviews\"     \n[21] \"language\"                  \"country\"                  \n[23] \"content_rating\"            \"budget\"                   \n[25] \"title_year\"                \"actor_2_facebook_likes\"   \n[27] \"imdb_score\"                \"aspect_ratio\"             \n[29] \"movie_facebook_likes\"     \n```\n\n\n:::\n\n```{.r .cell-code}\nls(imdbMessy) #order = alphabetical order\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"actor_1_facebook_likes\"    \"actor_1_name\"             \n [3] \"actor_2_facebook_likes\"    \"actor_2_name\"             \n [5] \"actor_3_facebook_likes\"    \"actor_3_name\"             \n [7] \"aspect_ratio\"              \"budget\"                   \n [9] \"cast_total_facebook_likes\" \"color\"                    \n[11] \"content_rating\"            \"country\"                  \n[13] \"director_facebook_likes\"   \"director_name\"            \n[15] \"duration\"                  \"facenumber_in_poster\"     \n[17] \"genres\"                    \"gross\"                    \n[19] \"imdb_score\"                \"language\"                 \n[21] \"movie_facebook_likes\"      \"movie_imdb_link\"          \n[23] \"movie_title\"               \"num_critic_for_reviews\"   \n[25] \"num_user_for_reviews\"      \"num_voted_users\"          \n[27] \"plot_keywords\"             \"title_year\"               \n```\n\n\n:::\n:::\n\n\n  \n</details>\n\\  \nc. Examine the color variable. What are the existing values? \n\n<details>\n  <summary>Solution</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimdbMessy %>% select(color) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 1\n  color\n  <chr>\n1 Color\n2 Color\n3 Color\n4 Color\n5 <NA> \n6 Color\n```\n\n\n:::\n\n```{.r .cell-code}\nlevels(factor(imdbMessy$color))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"B&W\"             \"Black and White\" \"color\"           \"Color\"          \n[5] \"COLOR\"          \n```\n\n\n:::\n\n```{.r .cell-code}\nunique(imdbMessy$color)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Color\"           NA                \"Black and White\" \"COLOR\"          \n[5] \"color\"           \"B&W\"            \n```\n\n\n:::\n:::\n\n\n  \n</details>\n\nd. How often does each color occur? *Hint:* `table` or `count` (which is a short hand for a `group_by`/`summarize(n=n())`)\n\n<details>\n  <summary>Solution</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimdbMessy %>% count(color)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 2\n  color               n\n  <chr>           <int>\n1 B&W                10\n2 Black and White   199\n3 COLOR              30\n4 Color            4755\n5 color              30\n6 <NA>               19\n```\n\n\n:::\n\n```{.r .cell-code}\ntable(imdbMessy$color)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n            B&W Black and White           color           Color           COLOR \n             10             199              30            4755              30 \n```\n\n\n:::\n:::\n\n\n  \n</details>\n\ne. The `read_csv` read in the `color` values as strings. For this exercise, let's convert them to factor using the code: `imdbMessy <- imdbMessy %>% mutate(color = factor(color))`.\n\n<details>\n  <summary>Solution</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimdbMessy <- imdbMessy %>% mutate(color = factor(color))\n```\n:::\n\n\n  \n</details>\n\nf. Select what you think is the best value for each level and replace \"messy\" versions of the value with clean ones with the `fct_recode` function as shown above. How many entries are there for each level now?\n\n<details>\n  <summary>Solution</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimdbMessy <- imdbMessy %>% mutate(color = fct_recode(color, \"B&W\" = \"Black and White\", \"Color\" = \"color\", \"Color\" = \"COLOR\"))\nimdbMessy %>% count(color)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n  color     n\n  <fct> <int>\n1 B&W     209\n2 Color  4815\n3 <NA>     19\n```\n\n\n:::\n:::\n\n\n  \n</details>\n\n**Addressing Missing Data**\n\nFinally, you should look for and address missing data, encoded as `NA` (not available) in `R`. There is no single formula for dealing with NAs. You should first look to see how many NAs appear in each column:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolSums(is.na(imdbMessy))\n```\n:::\n\n\n\nStudy the individual observations with NAs carefully. Why do you think they are missing? Are certain types of observations more likely to have NAs?\n\nYou have several options for dealing with NAs (*and they have different consequences*):\n\n* You can remove observations with one or more NAs (see [`drop_na`](https://tidyr.tidyverse.org/reference/drop_na.html)).\n* You can remove columns with many NA values.\n* You can replace NAs with a reasonable value (called *imputing* values). This could be a default value (like zero), or the average for a column. (see [`replace_na`](https://tidyr.tidyverse.org/reference/replace_na.html))\n* You can use packages such as `missForest` that fill in missing values with statistical predictions.^[This is dangerous unless you know what you are doing.]\n\nThere is no perfect approach to dealing with NAs, and you must *think carefully* about how removing or replacing missing data may affect your work.\n\n\n\n::: {.cell name='Address NA values in the Messy IMDB 5000 dataset'}\n\n```{.example .cell-code}\nConsider `imdbMessy`.\n```\n:::\n\n\n\na. Print out the number of NAs in each of the columns.\n\n\n<details>\n  <summary>Solution</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolSums(is.na(imdbMessy))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     ...1                     color             director_name \n                        0                        19                       104 \n   num_critic_for_reviews                  duration   director_facebook_likes \n                       50                        15                       104 \n   actor_3_facebook_likes              actor_2_name    actor_1_facebook_likes \n                       23                        13                         7 \n                    gross                    genres              actor_1_name \n                      884                         0                         7 \n              movie_title           num_voted_users cast_total_facebook_likes \n                        0                         0                         0 \n             actor_3_name      facenumber_in_poster             plot_keywords \n                       23                        13                       153 \n          movie_imdb_link      num_user_for_reviews                  language \n                        0                        21                        12 \n                  country            content_rating                    budget \n                        5                       303                       492 \n               title_year    actor_2_facebook_likes                imdb_score \n                      108                        13                         0 \n             aspect_ratio      movie_facebook_likes \n                      329                         0 \n```\n\n\n:::\n:::\n\n\n  \n</details>\n\n\nb. Consider the `actor_1_facebook_likes` column. Take a look at a few of the records that have NA values. Why do you think there are NAs?\n\n<details>\n  <summary>Solution</summary>\n\nThis variable is missing if `actor_1_name` is missing, which suggests that this movie doesn't have an actor 1 listed. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimdbMessy %>% filter(is.na(actor_1_facebook_likes)) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 x 29\n   ...1 color director_name     num_critic_for_reviews duration\n  <dbl> <fct> <chr>                              <dbl>    <dbl>\n1  4503 Color Léa Pool                              23       97\n2  4520 Color Harry Gantz                           12      105\n3  4721 Color U. Roberto Romano                      3       80\n4  4838 Color Pan Nalin                             15      102\n5  4946 Color Amal Al-Agroobi                       NA       62\n6  4947 Color Andrew Berends                        12       90\n# i 24 more variables: director_facebook_likes <dbl>,\n#   actor_3_facebook_likes <dbl>, actor_2_name <chr>,\n#   actor_1_facebook_likes <dbl>, gross <dbl>, genres <chr>,\n#   actor_1_name <chr>, movie_title <chr>, num_voted_users <dbl>,\n#   cast_total_facebook_likes <dbl>, actor_3_name <chr>,\n#   facenumber_in_poster <dbl>, plot_keywords <chr>, movie_imdb_link <chr>,\n#   num_user_for_reviews <dbl>, language <chr>, country <chr>, ...\n```\n\n\n:::\n:::\n\n\n  \n</details>\n\nc. Create a new dataframe that removes observations that have NAs for `actor_1_facebook_likes`.\n\n<details>\n  <summary>Solution</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimdbMessysub <- imdbMessy %>% filter(!is.na(actor_1_facebook_likes))  #Notice how I saved this new smaller dataset to a new name\n```\n:::\n\n\n  \n</details>\n\nd. Create a second new data frame that replaces NAs in `actor_1_facebook_likes` with 0.\n\n<details>\n  <summary>Solution</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimdbMessysub2 <- imdbMessy %>% mutate(actor_1_facebook_likes = replace_na(actor_1_facebook_likes,0))  \n```\n:::\n\n\n  \n</details>\n\n## Additional Practice {-}\n\n\n\n::: {.cell}\n\n```{.exercise .cell-code}\nFind a dataset that is not built into `R` and is related to one of the following topics:  \n  \n```\n:::\n\n\n\n* A personal hobby or passion\n* Your hometown, or a place you have lived\n  \nLoad the data into `R`, make sure it is clean, and construct one interesting visualization of the data and include alt text.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}